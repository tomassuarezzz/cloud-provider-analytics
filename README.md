Cloud Provider Analytics â€” Data Lakehouse

Proyecto Final â€“ MinerÃ­a de Datos II
Autora: Agustina Nogueira
TecnologÃ­as: PySpark, Structured Streaming, Delta-like Lakehouse, AstraDB (Cassandra)

Este proyecto implementa un pipeline end-to-end para un proveedor de servicios cloud ficticio.
El objetivo es construir un Data Lakehouse con las capas Landing â†’ Bronze â†’ Silver â†’ Gold, incorporando ingesta batch + streaming, calidad de datos, curaciÃ³n, enriquecimiento y publicaciÃ³n final para consumo analÃ­tico.


ğŸš€ Objetivos del proyecto

âœ” Implementar un pipeline completo usando PySpark.

âœ” Ingerir y procesar datos en JSONL y CSV.

âœ” DiseÃ±ar un Data Lake con capas Bronze/Silver/Gold.

âœ” Detectar anomalÃ­as de costos mediante Z-score, MAD y percentil 99.

âœ” Construir marts analÃ­ticos orientados a FinOps.

âœ” Publicar los resultados en una base NoSQL (AstraDB / Cassandra).

âœ” Simular una ingesta continua con Structured Streaming.

ğŸ“‚ Estructura del repositorio


## ğŸ“‚ Estructura del repositorio

```text
cloud-provider-analytics/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ cloud_provider_pipeline.ipynb        # Pipeline ETL completo
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ cassandra_schema.cql                # Tablas para AstraDB / Cassandra
â”‚
â”œâ”€â”€ cloud_provider_dataset/                 # Datos fuente (CSV, JSONL)
â”‚
â”œâ”€â”€ datalake/
â”‚   â”œâ”€â”€ landing/                            # Llegada de archivos crudos
â”‚   â”œâ”€â”€ bronze/                             # NormalizaciÃ³n y calidad
â”‚   â”œâ”€â”€ silver/                             # Datos limpios y enriquecidos
â”‚   â””â”€â”€ gold/                               # Marts analÃ­ticos
â”‚
â””â”€â”€ README.md
```




ğŸ›  TecnologÃ­as utilizadas

- Python 3.10 / PySpark 3.5+
- Structured Streaming
- Google Colab
- Cassandra / AstraDB
- Parquet
- Lakehouse pattern basado en Parquet

  ğŸ§± Arquitectura del pipeline


  <img width="1900" height="1272" alt="image" src="https://github.com/user-attachments/assets/d7c525d7-bc6d-4fb2-81af-839e2b292dc2" />


1ï¸âƒ£ Landing Layer

Se ingestan archivos crudos desde el repositorio:

- events_batch_1/*.jsonl
- events_batch_2/*.jsonl
- CSV maestros: customers, users, resources, billing, NPS, tickets, marketing.

TambiÃ©n se configura un directorio dedicado para ingesta continua: datalake/landing/usage_events_stream/

2ï¸âƒ£ Bronze Layer

- NormalizaciÃ³n de tipos
- Agregado de columnas tÃ©cnicas (ingest_ts, source_file)
- Validaciones de calidad
- Quarantine para eventos de uso con schema invÃ¡lido
- Structured Streaming â†’ Bronze para simular trÃ¡fico real
- Particionamiento por event_date
  

Tablas Bronze principales:

| Tabla                                              | DescripciÃ³n                             |
| -------------------------------------------------- | --------------------------------------- |
| `usage_events`                                     | Eventos de uso vÃ¡lidos (stream + batch) |
| `quarantine_usage`                                 | Eventos rechazados con `invalid_reason` |
| `customers`, `users`, `resources`, `tickets`, etc. | Maestros normalizados                   |


3ï¸âƒ£ Silver Layer

Se generan datasets limpios y enriquecidos:

- usage_enriched = eventos de uso + datos del cliente
- Derivados: resoluciÃ³n de tickets, totales mensuales, features temporales
- ConversiÃ³n de unidades y costos

TambiÃ©n se construye:
org_daily_usage_by_service dataset agregado derivado de usage_enriched

Con agregaciones por:
- Cliente
- Fecha
- Servicio

Incluye mÃ©tricas:
- daily_cost_usd
- daily_genai_tokens
- daily_carbon_kg

Y features para anomalÃ­as:
- z_score_cost
- mad_cost, mad_score_cost
- p99_cost
- Flags: is_zscore_anomaly, is_mad_anomaly, is_p99_anomaly, is_any_anomaly

  4ï¸âƒ£ Gold Layer

Se crean marts orientados al anÃ¡lisis:

â­ finops_by_org_day
Incluye:
- costo diario por servicio
- uso de recursos
- almacenamiento
- compute
- tokens generados
- emisiones estimadas

â­ cost_anomaly_mart
Contiene:
- costo diario por servicio
- features estadÃ­sticos
- banderas de anomalÃ­a
- metadata del cliente (industria, regiÃ³n, lifecycle)

5ï¸âƒ£ Serving Layer (AstraDB / Cassandra)

Se dejan preparadas las celdas para:
- Crear tablas Cassandra
- Escribir tablas GOLD en AstraDB
- Validar lectura

Nota:
En Colab, el conector spark-cassandra-connector no estÃ¡ disponible por defecto.
El cÃ³digo es correcto, pero requiere ejecutarse en un entorno con el JAR configurado (cluster local o Databricks).

ğŸ“Š Resultados principales

- Pipeline completo de ingesta â†’ calidad â†’ enriquecimiento â†’ anÃ¡lisis.
- IdentificaciÃ³n automÃ¡tica de anomalÃ­as de costos por cliente y servicio.
- Mart Gold orientado a FinOps, Ãºtil para dashboards y monitoreo de costos.
- PreparaciÃ³n para publicar en Cassandra como base transaccional rÃ¡pida.

â–¶ï¸ CÃ³mo ejecutar este proyecto

1) Abrir notebooks/cloud_provider_pipeline.ipynb en Google Colab.
2) Ejecutar las celdas en orden desde arriba hacia abajo.
3) La secciÃ³n de Serving requiere un entorno con el conector de Cassandra.

 ğŸ“Œ Licencia

Uso acadÃ©mico â€“ MinerÃ­a de Datos II.  

